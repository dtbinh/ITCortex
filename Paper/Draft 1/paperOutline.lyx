#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
 \usepackage[singlelinecheck=false,justification=centering]{caption}
\usepackage{url}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip smallskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
TO DO
\end_layout

\begin_layout Enumerate

\emph on
Include Mikes kitchen model.
 Stored on Github at https://github.com/michaelmike123/V-rep.git.
 File format not regular VREP scene.
 Open on a windows machine and export to a regular VREP scene.
 
\end_layout

\begin_layout Enumerate

\emph on
Points in italic need review from Bryan.
\end_layout

\begin_layout Enumerate

\emph on
Some of the images are low quality - from old presentations.
 Original images for these need to be recaptured.
\end_layout

\begin_layout Enumerate

\emph on
Include reference to code: https://github.com/salkhan23/ITCortex.
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Itemize
IT Cortex background
\end_layout

\begin_deeper
\begin_layout Itemize
Objects in our natural visual experiences exhibit a variety of transformations
 - they can fall anywhere on the retina, appear at different distances,
 orientations, illuminations, occlusions, deformations, colors, outlines
 and often coexist with multiple objects.
 Despite these challenging viewing conditions, the brain can rapidly and
 effortlessly decode object identity.
 In the primate brain, visual information processing is known to progress
 along two pathways: the ventral 'what' stream and the dorsal 'where' stream.
 The Inferior Temporal (IT) cortex, located at the top end of the ventral
 stream, is thought to be responsible for object detection and recognition.
 Feed-forward input to the IT cortex consists of spikes from neurons in
 lower ventral stream layers.
 Given the variety of transformation objects display in complex environments
 and the variability in spike patterns of lower layer neurons, each IT object
 encounter can be considered unique, 
\begin_inset CommandInset citation
LatexCommand cite
key "dicarlo2012"

\end_inset

.
 Yet, object identity has been shown to be decodable from population responses
 of IT neurons using simple biologically plausible classifiers, 
\begin_inset CommandInset citation
LatexCommand cite
key "hung2005"

\end_inset

.
\end_layout

\begin_layout Itemize
This remarkable capability of the IT cortex was thought to extend to individual
 IT neurons as well.
 However, responses of individual IT neurons were found to be strongly impacted
 by these transformations.
 This lead to the contemporary view that the IT cortex, as a whole, encodes
 not only object identity but their attributes as well.
 How the IT cortex mechanistically achieves this is still not understood.
 Clearly there is a need to develop a strong understanding of how these
 transformations influence IT neuronal responses at both the individual
 and population level.
\end_layout

\end_deeper
\begin_layout Itemize
Background on specific problem
\end_layout

\begin_deeper
\begin_layout Itemize

\emph on
Tuning curves in the literature
\end_layout

\begin_deeper
\begin_layout Itemize
Often papers isolate one or two stimulus dimensions and present tuning profiles
 as stimuli change along the chosen dimension(s).
\end_layout

\begin_layout Itemize

\emph on
Why collect data from multiple tuning curves and combine into a single model.
\end_layout

\begin_layout Itemize

\emph on
Similar work: find articles that attempt to do this.
 If cant find any, why not.
 Drawbacks of approach.
 Why haven't people attempted this before?
\end_layout

\end_deeper
\begin_layout Itemize

\emph on
Why we can consider independent tuning curves and use the product to get
 net firing rate
\end_layout

\begin_layout Itemize

\emph on
Consider only inanimate objects
\end_layout

\begin_deeper
\begin_layout Itemize
We consider only inanimate objects.
 Localized clusters for animate objects have been identified in the IT cortex,
 while processing of inanimate objects appears to be more widely distributed.
 
\end_layout

\begin_layout Itemize
It has also been shown that IT neuronal response properties differ for these
 two categories.
\end_layout

\end_deeper
\begin_layout Itemize

\emph on
Single tuning profile for all objects
\end_layout

\begin_deeper
\begin_layout Itemize
All objects share a common tuning profile for each considered transformation.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "fujita1992"

\end_inset

 found that IT neurons were arranged in columnar structures that shared
 similarities in their preferences.
 We uses this as justification for a single tuning profile for all objects.
 
\end_layout

\begin_layout Itemize
In 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007,ito1995"

\end_inset

 it was found that object preference at least for the neurons most preferred
 object was mostly preserved under various transformations.
 Although they did notice some deviations from this general rule.
\end_layout

\end_deeper
\begin_layout Itemize

\emph on
What about noise correlations between nearby neurons.
 Why can we ignore these?
\end_layout

\begin_layout Itemize

\emph on
What about spatial arrangement of IT neurons.
 Our approach is to use statistical population properties rather than detailed
 spatial maps.
 Why not use spatial maps? drawbacks? problems? Why is this a good compromise?
\end_layout

\begin_layout Itemize

\emph on
We do not consider inhibitory and excitatory neurons separately.
 Why?
\end_layout

\end_deeper
\begin_layout Itemize
Comaprison with other IT models:
\end_layout

\begin_deeper
\begin_layout Itemize
Other models focus on object detection and classification capability of
 the IT cortex.
\end_layout

\begin_layout Itemize
Our emphasis is on modeling tuning properties and realistic firing patterns
 of IT neurons.
\end_layout

\begin_layout Itemize

\emph on
How does our model help/assist other IT cortex models?
\end_layout

\end_deeper
\begin_layout Itemize
Specific Objective
\end_layout

\begin_deeper
\begin_layout Itemize
Develop an integrated model that can replicate observed individual and populatio
n responses of the IT cortex given object ground truth in a scene.
 Specifically, we target: (1) object selectivity, (2) maximum fire rates,
 (3) position, (4) size, (5) orientation, (6) occlusion, (7) clutter and
 (8) dynamic responses of IT neurons.
\end_layout

\begin_deeper
\begin_layout Itemize

\emph on
Why have we chosen these specific transformations.
\end_layout

\begin_layout Itemize

\emph on
What about the others that have been left out.
 Is the plan to include those later?
\end_layout

\end_deeper
\begin_layout Itemize
Motivation for doing so (overall goal)
\end_layout

\end_deeper
\begin_layout Itemize
Methodology:
\end_layout

\begin_deeper
\begin_layout Itemize
For each tolerance, find statistical fit(s) for observed tuning profiles.
 
\end_layout

\begin_layout Itemize
For each statistical model develop models for distributions of their parameter(s
) and reproduce realistic population level responses.
 
\end_layout

\begin_layout Itemize
Use Virtual Robot Experimentation Platform (V-REP) to generate a complex
 visual scene and develop techniques for extracting and quantifying relevant
 ground truth (identity + attributes) from scenes.
 
\end_layout

\end_deeper
\begin_layout Section
Methods
\end_layout

\begin_layout Subsection
Selection Criteria for Literature Results to model
\end_layout

\begin_layout Itemize

\emph on
Chose results that provided the highest granularity and most extensive results
 for the stimulus dimension of interest.
\end_layout

\begin_layout Itemize

\emph on
Explain techniques used to align results from different papers, as some
 properties are quantified differently.
\end_layout

\begin_layout Itemize

\emph on
Data from references was extracted using WebPlotDigitier 
\begin_inset CommandInset citation
LatexCommand cite
key "WebPlotDigitizer"

\end_inset

.
 Fix this reference.
\end_layout

\begin_layout Subsection
Tuning Profiles
\end_layout

\begin_layout Subsubsection
Selectivity
\end_layout

\begin_layout Itemize
It is well established that IT neurons respond to stimuli more complex then
 those of lower layers 
\begin_inset CommandInset citation
LatexCommand cite
key "tanaka1996"

\end_inset

.
 
\end_layout

\begin_layout Itemize
Neurophysiological studies typically test IT neurons with a range of different
 objects across a broad range of object categories.
\end_layout

\begin_layout Itemize
It has prooven difficult to come up a single consistent quantification of
 object identity.
\end_layout

\begin_layout Itemize
A common characterization of object identity, that goes around having to
 identify its dimensionality, is the percentage of objects a neuron responds
 with above background activity levels among the total stimuli set, objects
 it is selective for.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011,zoccolan2007"

\end_inset

 both recorded a wide range of object selectivities using different metrics.
\end_layout

\begin_layout Itemize
We quantified selectivity over objects of model neurons by excess Kurtosis
 - a measure of the peak sharpness and tail heaviness of a distribution.
 A distribution with a high Kurtosis generates large responses (peak sharpness)
 for a few object while most objects generate minimal respones (tail heaviness).
 While a distribution with a low Kurtosis responds similarly to several
 objects (broad peaks) while no discernible responses for the rest (small
 tails).
\end_layout

\begin_layout Standard
\align center
\begin_inset Formula 
\begin{equation}
SI_{K}=\frac{\sum_{i=1}^{N}(r_{i}-\bar{r})^{4}}{Ns^{4}}-3
\end{equation}

\end_inset

 
\end_layout

\begin_layout Standard
Where
\end_layout

\begin_layout Standard
\begin_inset Formula $r_{i}$
\end_inset

 is the response of the neuron to the 
\begin_inset Formula $ith$
\end_inset

 test stimulus,
\end_layout

\begin_layout Standard
\begin_inset Formula $\bar{r}$
\end_inset

 average response of the neuron across all stimuli,
\end_layout

\begin_layout Standard
\begin_inset Formula $s$
\end_inset

 is the standard deviation of the responses,
\end_layout

\begin_layout Standard
\begin_inset Formula $N$
\end_inset

 is the number stimuli.
\end_layout

\begin_layout Standard
In case of population sparseness, 
\end_layout

\begin_layout Standard
\begin_inset Formula $r_{i}$
\end_inset

 is the response to the 
\begin_inset Formula $ith$
\end_inset

 model neuron,
\end_layout

\begin_layout Standard
\begin_inset Formula $\bar{r}$
\end_inset

 average response to the test stimulus, 
\end_layout

\begin_layout Standard
\begin_inset Formula $s$
\end_inset

 is the standard deviation of responses to the test stimulus,
\end_layout

\begin_layout Standard
\begin_inset Formula $N$
\end_inset

 is the number of neurons.
\end_layout

\begin_layout Itemize
Population sparseness, population responses to a specific stimulus, was
 also quantified by excess Kurtosis.
 It was found in 
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011"

\end_inset

 that population spareness was typically higher than neuronal selectivity.
 Hence a visible object typically generates large responses from a few neurons,
 while individually, neurons respond to several objects.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011"

\end_inset

 also observed that population average response to individual test stimuli
 were similar but different neurons responded well to different stimuli.
 They concluded that object identities are encoded in the activity patterns
 of the population and not by mean population responses.
 
\emph on
(Can get figure for this result - plot of average fire rates for different
 objects and multiple plots of firing rates of individual neurons to diffrent
 stimuli.)
\end_layout

\begin_layout Itemize
Similar to 
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011"

\end_inset

, neuronal selectivities over objects are modeled as Gamma probability distribut
ions.
 
\end_layout

\begin_layout Itemize
The authors justify the selection of a gamma distribution with different
 scale and shape parameters to create a statistically inhomogenous population
 of neurons which they show is necessary to achieve the result population
 sparseness is greater than individual neuronal selectivity
\emph on
.
\end_layout

\begin_layout Itemize
Distributions for shape and scale parameters for the gamma selectivity profile
 were also modeled as Gamma distributions.
 Parameters for their distributions were based on values from 
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011"

\end_inset

 but were optimized to account for non-optimal position and size of their
 test stimuli.
 
\end_layout

\begin_deeper
\begin_layout Itemize
non-optimal position: all stimuli were presented foveally.
 However the receptive field centers of IT neurons, their optimal positions,
 are distributed around the fovea.
 To account for this we created a large sample of position profiles and
 determine the amount of deviation expected if stimuli are presented at
 (0, 0) to all neurons.
\end_layout

\begin_layout Itemize
non-optimal size: The largest dimension of all test stimuli extended 7
\begin_inset Formula $\textdegree$
\end_inset

 degrees.
 To account for this we generate a large sample of size tuning profiles
 of IT neurons and determine the amount of deviation expected if stimuli
 are presented with a size of 7
\begin_inset Formula $\textdegree$
\end_inset

 degrees.
\end_layout

\begin_layout Itemize
Finally the mean and variance of these deviations were calculated and used
 to adjust the shape and scale distribution parameters.
 
\emph on
Add more details on how the mean and variance of the deviations was used
 and what is adjusted because of them [Bryan].
\end_layout

\begin_layout Itemize

\emph on
Also what is the impact of this modified distributions? lower Kurtosis across
 the population compared to Lehky Kurtosis distribution?
\end_layout

\end_deeper
\begin_layout Itemize
A second measure of neuron selectivity, the activity fraction 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

, was also calculated for each model neuron.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
SI_{AF}=\frac{(N-1)}{N}\left(1-\frac{\left(\sum\frac{r_{i}}{N}\right){}^{2}}{{\textstyle \sum}\frac{r_{i}^{2}}{N}}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\end_layout

\begin_layout Standard
\begin_inset Formula $r_{i}$
\end_inset

 is the response to the 
\begin_inset Formula $ith$
\end_inset

 stimulus 
\end_layout

\begin_layout Standard
\begin_inset Formula $N$
\end_inset

 is the number of test stimuli.
\end_layout

\begin_layout Itemize
Activity fractions range between [0, 1].
 A neuron with an activity fraction of 0 responds equally to all stimuli
 (less selective) while a neuron with a selectivity index of 1 shows preference
 to a few stimuli only (highly selective).
 
\end_layout

\begin_layout Itemize
Neuron selectivity assessed as the activity fraction was used to model decreases
 in tolerances as selectivity increases in several tuning profile as observed
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

.
 
\end_layout

\begin_layout Itemize
At initialization, a list of all objects in the scene is passed into each
 model neuron.
 The neuron randomly assigns a value between (0, 1) to each object.
 We use the inverse of the cumulative distribution function (CDF) of the
 neurons selectivity profile normalized by its maximum value to find the
 neurons preference for each object.
\end_layout

\begin_layout Subsubsection
Maximum Firing Rate
\end_layout

\begin_layout Itemize
The selectivity profile of model neurons was also used to generate their
 maximum firing rates.
 
\end_layout

\begin_layout Itemize
The inverse CDF was used to determine the unnormalized selectivity at which
 the CDF is 0.99.
\end_layout

\begin_layout Itemize
This was used as the maximum firing rate of model neurons.
\end_layout

\begin_layout Itemize

\emph on
Other then the convenience of using the selectivity distribution for deriving
 the maximum fire rate distribution, need to come up with a model that models
 the literature or some property of IT neurons.
\end_layout

\begin_deeper
\begin_layout Itemize

\emph on
Candidate: 
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011"

\end_inset

 found a strong negative correlation between an IT neurons selectivity (Kurtosis
) and their mean response across all stimuli.
 As a neuron becomes more selective its mean firing rate decreases, Figure
 5Ai.
 Our current maximum firing rate model (selectivity where CDF=0.99) does
 not clearly model this observation.
 A highly selective neuron will have a gamma distribution with a high Kurtosis.
 Because high Kurtosis distributions have long tails, its selectivity at
 CDF=0.99 will also be a large.
 Hence, the more selective a neuron, higher is maximum firing rate.
 Although a highly selective neuron may still have a low average firing
 rate, because a few neurons return responses close to maximum and the average
 is taken over all the objects.
 The average response of less selective neurons may also be low - several
 stimuli have similar responses, but the majority have no responses.
 Maybe average firing rate verses selectivity is not a good measure.
 Somehow we need to model this result in a clearer way.
\end_layout

\begin_layout Itemize

\emph on
Currently the overall model is showing low firing rates, possibly due to
 the our max fire rate model.
\end_layout

\begin_layout Itemize

\emph on
Need to plot the average firing rate versus Kurtosis selectivity and see
 if our model agrees with this result.
\end_layout

\end_deeper
\begin_layout Subsubsection
Position
\end_layout

\begin_layout Itemize
Spatial receptive fields were modeled as normalized 2D Gaussian distributions
 with parameters receptive field center and position tolerance.
 
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "op2000"

\end_inset

 found that receptive field centers, preferred object locations, were distribute
d around the fovea with a slight bias towards the contralateral visual hemispher
e.
 Coordinates (X, Y) of the receptive field center were modeled as Gaussian
 distributions.
 Parameters of these distribution were estimated by least square error (LSE)
 fitting of the receptive field center of masses of 
\begin_inset CommandInset citation
LatexCommand cite
key "op2000"

\end_inset

.
 x 
\begin_inset Formula $\sim$
\end_inset


\begin_inset Formula $N$
\end_inset

(1.82, 2.02), y 
\begin_inset Formula $\sim$
\end_inset


\begin_inset Formula $N$
\end_inset

(0.62, 2.12).
 Where x, y are in degrees of eccentricity from the fovea.
\end_layout

\begin_layout Itemize
The position tolerance, the extent of the spatial receptive field was quantified
 as twice the standard deviation of the underlying Gaussian distribution.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "op2000,zoccolan2007"

\end_inset

 both observed a broad range of position tolerances across the population.
 
\end_layout

\begin_layout Itemize
Spatial extent in the x and y direction of receptive fields were found to
 be similar in 
\begin_inset CommandInset citation
LatexCommand cite
key "op2000"

\end_inset

 and we use a single position tolerance for both.
\end_layout

\begin_layout Itemize
A Gamma distribution was used to model the position tolerance distribution.
 To find the parameters of this distribution first we did a linear regression
 fit of the position tolerance versus neuron selectivity (activity fraction)
 scatter plot of 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

.
 This was used to model how mean position tolerance decreases with activity
 fraction selectivity.
 Second we assumed the shape parameter of the distribution was fixed and
 the scale parameter, derived from the mean, decreased with selectivity.
 Finally we used maximum likelihood estimation to find the best fit shape
 and scale parameters subject to the above constraints.
 This models two effects seen in the data: average position tolerance decreased
 with selectivity and variance from the mean decreases with selectivity
 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

.
 
\end_layout

\begin_layout Itemize
The normalized position firing rate of is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{position}(x,y)=\exp\left(\frac{-\left((x-x_{c})^{2}+(y-y_{c})^{2}\right)}{2\sigma_{PT}}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $x,\,y$
\end_inset

 are the position coordinates of the stimulus in the x and y in radians
 of eccentricity,
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{c},y_{c}$
\end_inset

 is the receptive field center of postion tuning profile,
\end_layout

\begin_layout Standard
\begin_inset Formula $\sigma_{PT}$
\end_inset

 is the position tolerance of the neuron in radians of eccentricity.
\end_layout

\begin_layout Itemize
For each model neuron the spatial extent of the receptive field was also
 quantified by the square root of its area.
 Here the area of the receptive field was defined by a circle with radius
 equal to the position tolerance.
 
\emph on
Currently we use half the position tolerance to define the area.
 Change to position tolerance only.
 Our size tuning model uses this to determine the maximum size of stimulus
 that it can respond to.
\end_layout

\begin_layout Itemize

\emph on
Because we cannot generate activity fraction > 0.6, in our model by using
 the activity fraction to determine the receptive field size, the model
 may not be able to generate some of the larger receptive fields seen in
 the IT cortex by 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

.
 Need to investigate further.
\end_layout

\begin_layout Subsubsection
Size
\end_layout

\begin_layout Itemize
Size tolerance of model neurons was modeled as lognormal distributions with
 parameters preferred stimulus size and size bandwidth.
 
\emph on
Why is this profile log normally distributed but other tuning profiles are
 symmetric on the linear scale.
\end_layout

\begin_layout Itemize
Stimulus size was quantified as the distance between the outer edges along
 the longest axis of the stimulus.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "ito1995"

\end_inset

 found a wide range of preferred stimulus sizes and found little correlation
 with the neurons spatial receptive field size.
 Although preferred stimulus sizes were generally smaller.
\end_layout

\begin_layout Itemize
A lognormal distribution was used to model preferred stimulus sizes.
 Across their population of IT neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "ito1995"

\end_inset

 found two peaks, at preferred stimulus size 3.4 and 27 degrees.
 However, we ignored preferred sizes that were greater than or equal to
 27
\begin_inset Formula $\textdegree$
\end_inset

.
 These sizes were close to the largest stimulus size and several neurons
 had receptive field sizes that could accommodate much larger stimuli.
 It is likely that the preferred stimulus size of these neurons would be
 different if larger stimuli were used.
 This is not to say that preferred sizes cannot be greater than 27
\begin_inset Formula $\textdegree$
\end_inset

 are not generated, but that the frequency of their occurrence follows the
 distribution and trends seen at lower sizes.
 Parameters for the preferred stimulus sizes distribution were then determined
 by maximum likelihood fitting of the remaining data.
\end_layout

\begin_layout Itemize
Size bandwidth was quantified as the distance between the upper and lower
 half magnitude responses of a neurons size tuning profile in octaves.
 
\end_layout

\begin_layout Itemize
Little correlation was found between a neurons size bandwidth and its receptive
 field size.
\end_layout

\begin_layout Itemize
A lognormal distribution was also used to model the distribution of size
 bandwidths.
 Parameters for this distribution were determined by maximum likelihood
 fitting of size bandwidths measured in 
\begin_inset CommandInset citation
LatexCommand cite
key "ito1995"

\end_inset

.
 
\end_layout

\begin_layout Itemize
Parameters of the lognormal size tuning profile are derived from a neurons
 preferred stimulus size and size bandwidths as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\mu_{s}=log_{2}(preferred\,stimulus\,size)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\sigma_{ST}=\frac{size\,bandwidth}{\sqrt{2\ln(2)}}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
The normalized size firing rate is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{size}(s)=\begin{cases}
\begin{array}{cc}
\exp\left(\frac{-\left(\log_{2}(s)-\mu_{s}\right)^{2}}{2\sigma_{ST}^{2}}\right) & \,\mbox{if \ensuremath{s\leq s_{max}} }\\
0 & otherwise
\end{array}\end{cases}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $s$
\end_inset

 is the size of the stimulus defined as the maximum distance between the
 outer edges of the stimulus along the x, y, or z dimension in radians of
 eccentricity,
\end_layout

\begin_layout Standard
\begin_inset Formula $\mu_{s}$
\end_inset

 is the preferred stimulus size in radians of eccentricity,
\end_layout

\begin_layout Standard
\begin_inset Formula $\sigma_{ST}$
\end_inset

 is the size tolerance of the neuron in radians of eccentricity.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $s_{max}=2\sigma_{PT}$
\end_inset

 is the maximum stimulus size that can fit within the receptive field of
 the neuron.
\end_layout

\begin_layout Standard
Note that we model the distribution as a normal distribution by taking the
 logarithm of the input stimulus size.
\end_layout

\begin_layout Itemize
The spatial receptive field defined in terms of its areal extent was used
 to determine a maximum stimulus size, its diameter, for each neuron.
 Responses to all stimuli of size above this maximum were masked.
 
\emph on
Should this be taken out/modified? (1) There should be a gradual decrease
 in firing rate as the stimulus increased to a size greater than the maximum,
 rather then a sharp cutoff.
 Diffrent mask? (2) can we say that recorded tuning curves of this type
 were not completely measured.
\end_layout

\begin_layout Itemize

\emph on
A negative correlation between activity fraction selectivity and size tolerance
 was observed by 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

.
 Size tolerance was quantified as the drop in firing rate as the size changes
 from the optimal size of a neuron.
 Currently this is not included in the model, it would be useful to include
 as done for position tolerance.
 Although the range of sizes test (1, 2, 4, and 6
\begin_inset Formula $\textdegree$
\end_inset

) is much smaller than the range of sizes tested in 
\begin_inset CommandInset citation
LatexCommand cite
key "op2000"

\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Orientation
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "logothetis1995"

\end_inset

 found that IT neurons typically had a preferred view of an object - most
 familiar view - and their responses gradually declined as views rotated
 away.
\end_layout

\begin_layout Itemize
This preference persisted even as the monkey gained familiarity with the
 object and developed view invariant recognition at the behavioral level.
\end_layout

\begin_layout Itemize
Individual IT neurons developed preferences for different views.
\end_layout

\begin_layout Itemize
We model the base rotation tuning profile of IT neurons as a single Gaussian
 distribution with parameters preferred view and rotational tolerance.
\end_layout

\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "logothetis1995"

\end_inset

 also found that the tuning curves of some neurons were centered around
 two views.
 In all such cases, peak views displayed some level of symmetry, including
 mirror symmetry.
 Test objects were irregular wire or amoeboid objects.
 Because the objects were never completely symmetrical, their bi-modal tuning
 curves had amplitude differences between peaks.
\end_layout

\begin_layout Itemize
We do not model level of symmetry between views and use a binary metric
 to judge similarity.
 All symmetric views share the same peak amplitude and we do not model amplitude
 differences between peaks.
\end_layout

\begin_layout Itemize
A few neurons also displayed view invariant responses to all object views.
 A sample view invariant tuning curve is shown in 
\begin_inset CommandInset citation
LatexCommand cite
key "logothetis1995"

\end_inset

, however the object is not shown and it cannot be determined whether the
 symmetry of the object contributed to this view invariance.
 
\end_layout

\begin_layout Itemize
We assume multiple peaks in tuning curves are the result of symmetries in
 views of the object.
 From a neurons perspective, there is still a single preferred view and
 responses to views is based on how similar the view is to its most preferred
 view rather than absolute orientation.
\end_layout

\begin_layout Itemize
To model symmetric objects, we assume each object defines a period of symmetry
 around the x, y, and z axis.
 Where the symmetry period is defined as the number of views within a 360
\begin_inset Formula $\textdegree$
\end_inset

 rotation about the target axis that are identical to the preferred view.
\end_layout

\begin_layout Itemize
Within the symmetry period each object view is distinguishable as a deviation
 from a model neurons preferred orientation.
 While an orientation outside maps to a view within the symmetry period.
 
\end_layout

\begin_layout Itemize
Mirror symmetric objects are modeled as the sum of two Gaussian distributions
 with the second Gaussian centered around the mirror symmetric preferred
 view and with equal rotational tolerance.
\end_layout

\begin_layout Itemize
Each neuron then has a single rotation tuning curve that ranges from 
\begin_inset Formula $(-\pi,\,\pi)$
\end_inset

 for all objects it is selective for.
 However if an individual object defines a period of symmetry it will only
 see a partial view of the complete tuning profile within the defined period
 of symmetry about its preferred view.
 We assume symmetric tuning of orientations away from the preferred view
 in both directions.
\end_layout

\begin_layout Itemize
The normalized rotation firing rate is given by:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{rotation}(\theta,p_{sym},m_{sym})=\exp\left(\frac{-\left(\theta_{adj}-\mu_{r}\right)^{2}}{2\sigma_{RT}^{2}}\right)+m_{sym}\exp\left(\frac{-\left(\theta_{adj}-\mu_{r'}\right)^{2}}{2\sigma_{RT}^{2}}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where:
\end_layout

\begin_layout Standard
\begin_inset Formula $\theta$
\end_inset

 is the orientation of the object about the target axis in radians,
\end_layout

\begin_layout Standard
\begin_inset Formula $\theta_{adj}$
\end_inset

 is 
\begin_inset Formula $\theta$
\end_inset

 is adjusted to lie within the valid range of the symmetry period of the
 object.
 Valid range of the symmetry period is defined as 
\begin_inset Formula $\frac{2\pi}{p_{sym}}$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $\mu_{r}$
\end_inset

 is neurons preferred view of the object adjusted to lie within the symmetry
 period,
\end_layout

\begin_layout Standard
\begin_inset Formula $\sigma_{RT}$
\end_inset

 is the rotational tolerance of neuron in radians,
\end_layout

\begin_layout Standard
\begin_inset Formula $m_{sym}\in\{0,\,1\}$
\end_inset

 whether the object is mirror symmetric or not,
\end_layout

\begin_layout Standard
\begin_inset Formula $\mu_{r'}$
\end_inset

 mirror reflection of the neurons preferred view adjusted to lie within
 the symmetric period.
\end_layout

\begin_layout Itemize
The distribution of preferred orientation was modeled as uniform random
 variable within 
\begin_inset Formula $(-\pi,\pi)$
\end_inset

.
\end_layout

\begin_layout Itemize
In 
\begin_inset CommandInset citation
LatexCommand cite
key "logothetis1995"

\end_inset

, it was found that rotational tolerance, defined as the standard deviation
 of the fitted Gaussian distribution, around the x-axis and y-axis were
 similar and averaged 30
\begin_inset Formula $\textdegree$
\end_inset

 for both classes of tested objects.
 Absent any further details on distributions of rotational tolerances we
 model their distribution as a normal distribution with mean 30
\begin_inset Formula $\textdegree$
\end_inset

 and standard deviation of 50
\begin_inset Formula $\textdegree$
\end_inset

.
 
\emph on
Why was this value for standard deviation chosen.
\end_layout

\begin_layout Itemize
We also only model rotation tuning around y-axis and assume rotation tolerances
 about the x and z axis follower similar trends with their own preferred
 view, tolerances and symmetries.
\end_layout

\begin_layout Subsubsection
Occlusion
\end_layout

\begin_layout Itemize
Responses of IT neurons increase monotonically with object visibility 
\begin_inset CommandInset citation
LatexCommand cite
key "kovacs1995"

\end_inset

.
 
\end_layout

\begin_layout Itemize
IT neurons have also been shown to respond to object parts rather than the
 whole and prefer certain parts over others.
\end_layout

\begin_layout Itemize
These diagnostic parts are task dependant and behaviorally relevant to the
 task the monkey was actively attending.
\end_layout

\begin_layout Itemize
The level of preference for diagnostic parts varied across the population
 
\begin_inset CommandInset citation
LatexCommand cite
key "nielsen2006"

\end_inset

.
 
\end_layout

\begin_layout Itemize
However diagnostic parts were always preferred to nondiagnostic parts.
\end_layout

\begin_layout Itemize
To quantify an individual neurons preference for diagnostic parts, 
\begin_inset CommandInset citation
LatexCommand cite
key "nielsen2006"

\end_inset

 use the ratio of diagnostic group variance to total variance.
 Depending on which parts were visible, trials were grouped as diagnostic
 or nondiagnostic.
 The amount of the total variance that was explained by the between group
 variance quantified a neurons preference for diagnostic parts.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
R=\frac{Var_{diagnostic\,grouping}}{Var_{total}}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
Var_{diagnostic\,group}=\frac{1}{2}\left((\bar{f}_{diagnostic}-\bar{f})^{2}+(\bar{f}_{nondiagnostic}-\bar{f})^{2}\right)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $R$
\end_inset

 is the preference of the neuron for diagnostic object parts.
 Range (0, 1),
\end_layout

\begin_layout Standard
\begin_inset Formula $Var_{diagnostic\,group}$
\end_inset

 is the variance between diagnostic and nondiagnostic groups,
\end_layout

\begin_layout Standard
\begin_inset Formula $Var_{total}$
\end_inset

 is the variance across all trials,
\end_layout

\begin_layout Standard
\begin_inset Formula $\bar{f}$
\end_inset

 is the mean firing rate across all trials,
\end_layout

\begin_layout Standard
\begin_inset Formula $\bar{f}_{diagnostic}$
\end_inset

 is the firing rate across trials where only diagnostic parts were visible.
\end_layout

\begin_layout Standard
\begin_inset Formula $\bar{f}_{nondiagnostic}$
\end_inset

 is the firing rate across trials where only nondiagnostic parts were visible.
\end_layout

\begin_layout Itemize
A ratio of 1 means that the variance between groups is high, group mean
 firing rates are significantly difference from the overall mean, and the
 neuron shows a strong preference for diagnostic parts.
 While a ratio of 0 means there is no difference between group variances,
 group mean firing rates are the same as the overall mean, and the neuron
 responds equally to diagnostic and nondiagnostic parts.
\end_layout

\begin_layout Itemize
We model the occlusion tuning profile of model neurons as a two input Sigmoid
 with parameters 
\begin_inset Formula $w_{d},\,w_{nd}$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

.
 Where 
\begin_inset Formula $w_{d}$
\end_inset

 is the weight for the percentage of diagnostic parts that are visible,
 
\begin_inset Formula $w_{nd}$
\end_inset

 is the weight for nondiagnostic visibility and 
\begin_inset Formula $b$
\end_inset

 is a bias term.
\end_layout

\begin_layout Itemize
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{nd}$
\end_inset

 are chosen such that they can generate the desired preference for diagnostic
 parts.
 
\end_layout

\begin_layout Itemize
We used least square errors fitting on the scatter plot of 
\begin_inset Formula $R$
\end_inset

 in 
\begin_inset CommandInset citation
LatexCommand cite
key "nielsen2006"

\end_inset

 to fit an exponential distribution.
\end_layout

\begin_layout Itemize
We then used the inverse CDF of this distribution to generate a diagnostic
 parts preference ratio for each neuron.

\emph on
 Occasionally this inverse CDF generates a value greater then one and the
 code aborts.
 Not sure why.
 Implementation appears to be correct.
\end_layout

\begin_layout Itemize
This is still underconstraint to generate 
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{nd}$
\end_inset

 as there is no bounds on the ranges and neither is there any relation between
 
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{nd}$
\end_inset

.
 
\emph on
Can we use scipy.optimize.curve_fit to directly find a set of 
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{nd}$
\end_inset

 without having to rely on 
\begin_inset Formula $w_{c}$
\end_inset

? 
\end_layout

\begin_layout Itemize
To overcome this, we looked at occlusion tuning curves of IT neurons from
 other references.
 
\end_layout

\begin_layout Itemize
In 
\begin_inset CommandInset citation
LatexCommand cite
key "kovacs1995"

\end_inset

 tuning curves for multiple neurons to several occluded objects were recorded.
 However, diagnostic and non-diagnostic visibilities were not considered
 separately and a single visibility measure was used.
\end_layout

\begin_layout Itemize
We assume equal visibilities for diagnostic and nondiagnostic parts and
 use least square error fitting to fit all tuning curves to a single input
 Sigmoid with parameters 
\begin_inset Formula $w_{c}$
\end_inset

 and b.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{occlusion}(v_{c})=\sigma(w_{c}v_{c}+b)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $v_{c}=\sqrt{v_{d}^{2}+v_{nd}^{2}}$
\end_inset

 is the combined visibility of diagnostic and nondiagnostic parts of the
 object.
 If we assume equal visibilities for diagnostic and nondiagnostic parts,
 
\begin_inset Formula $v_{c}=\sqrt{2}v_{d}=\sqrt{2}v_{nd}$
\end_inset

.
 Note that 
\begin_inset Formula $v_{c}$
\end_inset

 ranges between 
\begin_inset Formula $(0,\,\sqrt{2})$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $w_{c}$
\end_inset

 is the weight along the combined visibility axis where 
\begin_inset Formula $v_{nd}=v_{d}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $\sigma(x)=\frac{1}{1+\exp(x)}$
\end_inset

 is the Sigmoid function.
\end_layout

\begin_layout Itemize
We found the mean and variance for 
\begin_inset Formula $w_{c}$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 across all tuning curves.
 We then assumed separate normal distributions for the combined weight and
 the bias terms.
\end_layout

\begin_layout Itemize
We assume the three weights are related though 
\begin_inset Formula $\sqrt{2}w_{c}=w_{n}+w_{d}$
\end_inset

.
 
\emph on
How did we derive this relation.
 Need to properly explain.
 [Bryan].
\end_layout

\begin_layout Itemize
Given 
\begin_inset Formula $w_{c},\,b$
\end_inset

 and 
\begin_inset Formula $R$
\end_inset

 for each neuron we use nonlinear optimization to determine a set of 
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{nd}$
\end_inset

 that can generate a between group variance of R.
 The nonlinear optimization technique used is the root finder function fsolve
 of Scipy's Optimize library where we find the roots of the function that
 calculates the diagnostic preference ratio given a set of 
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{n}$
\end_inset

and subtracts it from the target ratio.
 Initial estimate of the search for parameters is half the combined weight.
\end_layout

\begin_layout Itemize
Occasionally the optimization technique is unable to determine a set of
 
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{nd}$
\end_inset

 that can generate the required preference ratio.
 In such case we incease 
\begin_inset Formula $w_{c}$
\end_inset

 until a value is found that can reproduced the target ratio.

\emph on
 In the simulation we increase 
\begin_inset Formula $w_{c}$
\end_inset

 in steps of 2 until for up to 100 iterations.
 Unfortunately if a very high ratio is required this method still fails
 and the program aborts.
 Need a better way to search for 
\begin_inset Formula $w_{c}$
\end_inset

 so the program doesn't crash.
 We do not worry to much about following the distribution of w_c or b.
\end_layout

\begin_layout Itemize
The normalized occlusion firing rate of a neuron is then given by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{occlusion}(\mathbf{v})=\sigma(\mathbf{v.w}+b)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $\mathbf{v}=\left[\begin{array}{c}
v_{nd}\\
v_{d}
\end{array}\right]$
\end_inset

 is a vector of nondiagnostic and diagnostic visibility,
\end_layout

\begin_layout Standard
\begin_inset Formula $w=\left[\begin{array}{c}
w_{nd}\\
w_{d}
\end{array}\right]$
\end_inset

is a vector of diagnostic and nondiagnostic weights,
\end_layout

\begin_layout Standard
\begin_inset Formula $\mathbf{.}$
\end_inset

 is the dot product,
\end_layout

\begin_layout Standard
\begin_inset Formula $b$
\end_inset

 is the bias term.
\end_layout

\begin_layout Itemize

\emph on
This method of generating occlusion tuning curves is too convoluted.
 It may be hard to convince why this is a good model.
 Need to come up with a simpler way or justify why this is a good model.
\end_layout

\begin_layout Itemize
Responses of IT neurons are also known to take longer times to develop when
 objects are occluded 
\begin_inset CommandInset citation
LatexCommand cite
key "kovacs1995,nielsen2006"

\end_inset

.
 We do not model the additional latencies seen in responses of IT neurons.
 
\emph on
Why?
\end_layout

\begin_layout Subsubsection
Clutter
\end_layout

\begin_layout Itemize
Responses of IT neurons are know to be influenced by nearby objects.
 
\end_layout

\begin_layout Itemize
Response attenuation is also seen from objects which individually do not
 elicit responses.
 
\end_layout

\begin_layout Itemize
IT neuronal responses have also been shown to be impacted by background
 complexity 
\begin_inset CommandInset citation
LatexCommand cite
key "rolls2003"

\end_inset

.
\end_layout

\begin_layout Itemize
Under limited clutter conditions, two to three objects over a plain background,
 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2005"

\end_inset

 showed that responses of individual and populations of IT neurons to multiple
 objects were smaller than the linear sum of isolated responses and were
 much closer to the average of responses to constituent objects in isolation.
 Multiple averaging rules were tried in 
\begin_inset CommandInset citation
LatexCommand cite
key "li2009"

\end_inset

 and it was consistently found that all averaging models better fit recorded
 responses compared with models base on the linear sum of isolated respones.
\end_layout

\begin_layout Itemize
To model the clutter response of a model neuron, first its isolated response
 is calculated for all objects,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{isolated}(obj_{m})=R_{max}*pref_{obj_{m}}*r_{position}(x,y)*r_{size}(s)*r_{rotation}(\theta,p_{sym},m_{sym})*r_{occlusion}(\mathbf{v})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\end_layout

\begin_layout Standard
\begin_inset Formula $ground\,truth=x,y,s,\theta,p_{sym},m_{sym},v_{nd,}v_{d}$
\end_inset

, is the ground truth for object 
\begin_inset Formula $m$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $pref_{obj_{m}}$
\end_inset

 is the neurons normalized selectivity for object 
\begin_inset Formula $m$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $R_{max}$
\end_inset

 is the maximum firing rate of the neuron.
\end_layout

\begin_layout Itemize
Next isolated responses are weighted by normalized position responses and
 averaged to get the static response of neuron 
\begin_inset Formula $n$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
r_{static}=\frac{\sum_{m}^{M}w_{position\,obj_{m}}(x,y)*r_{isolated}(obj_{m})}{\sum_{m}^{M}w_{position\,obj_{m}}(x,y)}+d
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $w_{position\,obj_{m}(x,y)=}r_{position}(x,y)$
\end_inset

 for object 
\begin_inset Formula $m$
\end_inset

,
\end_layout

\begin_layout Standard
\begin_inset Formula $M$
\end_inset

 is the number of objects in the scene.
\end_layout

\begin_layout Standard
\begin_inset Formula $d$
\end_inset

 is a random variable that models the deviation from the averaging rule.
\end_layout

\begin_layout Itemize
Scatter plots of joint responses to two and three objects in 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2005"

\end_inset

 plotted against the isolated responses were used to find 
\begin_inset Formula $d$
\end_inset

.
 First the deviation of joint responses from the averaged isolated responses
 was found.
 A normal distribution with mean 0 and the standard deviation measured from
 the deviations was used to model 
\begin_inset Formula $d$
\end_inset

.
\end_layout

\begin_layout Itemize
By weighting isolated responses with their position weights, clutter responses
 are impacted by any object within their receptive field regardless of whether
 the neuron is selective for that object in isolation or not.
\end_layout

\begin_layout Itemize
We do not model the impact of background on clutter responses.
\end_layout

\begin_layout Itemize

\emph on
In 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

, it was found that the clutter responses of IT neurons also decrease with
 activity fraction selectivity.
 Should the impact of selectivity be included in the clutter response?
\end_layout

\begin_layout Subsubsection
Dynamics
\end_layout

\begin_layout Itemize

\emph on
[Bryan]
\end_layout

\begin_layout Itemize
\begin_inset Formula $r_{net}(t)=r_{dynamic}(t)=f(r_{static})=?$
\end_inset


\end_layout

\begin_layout Itemize

\emph on
Timestep used was 5ms.
 But is changeable.
\end_layout

\begin_layout Subsection
Overall Model
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Figures/IT Cortex Software Model.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\emph on
Overall Model.
 Figure needs some updating to use symbol notations in this paper.
 Also we need the rotation symmetries of the objects which are not included
 in the ground truth above.
 Red and green fount items are not readable in printed document- change
 font & color.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\emph on
Complete me
\end_layout

\begin_layout Subsection
Ground Truth Generation and Extraction
\end_layout

\begin_layout Itemize
A test scene in Virtual Robot Experimentation Platform (VREP) 
\begin_inset CommandInset citation
LatexCommand cite
key "vrep"

\end_inset

 is used to generate ground truth for the IT cortex model.
\end_layout

\begin_layout Itemize
Several objects were placed randomly in the scene along with the IT cortex
 robot.
\end_layout

\begin_layout Itemize
The IT cortex robot consisted of a vision sensor attached to an existing
 mobile robot (pioneer p3dx).
\end_layout

\begin_layout Itemize
The main job of the robot was to give mobility to the vision sensor.
\end_layout

\begin_layout Itemize
The vision sensor has an adjustable projection plane onto which it does
 a 2D rendering of its perspective of the 3D test scene.
\end_layout

\begin_layout Itemize
The sequence of 2D images from the vision sensors projection plane is the
 input stream from which ground truth is extracted.
\end_layout

\begin_layout Itemize
Rather than use some of VREPs built in object detection algorithms, a camera
 plane projection matrix is used to determine objects that lie on the projection
 plane.
 This reduces computational complexity.
\end_layout

\begin_layout Itemize
The VREP simulation was run in synchronous mode with a timestep specified
 by the IT cortex model.
\end_layout

\begin_layout Itemize
Default timestep was set to 5ms.
\end_layout

\begin_layout Itemize
At initialization, the VREP simulation is queried for a list of all objects
 in the scene.
\end_layout

\begin_layout Itemize
Constant object attributes are also determined.
 This include the size of the object which is defined as twice the maximum
 length in the x, y or z dimension, the rotation symmetries (rotation period
 and mirror symmetric) in the x, y and z dimension and the object handles
 of all objects and their component parts.
\end_layout

\begin_layout Itemize
Object rotation symmetries are added manually under the custom data field.
 If no rotation symmetries are retrieved, defaults of rotation symmetry
 of one and not mirror symmetric are assumed.
\end_layout

\begin_layout Itemize
A population of model neurons that is selective for these objects is then
 generated.
 Default population size is 100 neurons.
\end_layout

\begin_layout Itemize
Each timestep the IT cortex model triggers the VREP simulation to run and
 queries it for ground truth using VREPs remote APIs.
\end_layout

\begin_layout Itemize
To get projection plane coordinates of each object 
\begin_inset Formula $(x_{p},\,y_{p})$
\end_inset

, the coordinates of the objects center of mass in the reference frame of
 the vision center 
\begin_inset Formula $(x,\,y,\,z)$
\end_inset

 is retrieved.
 Where the reference frame of the vision system is a coordinate system with
 its origin at the center of mass of the vision sensor.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\left[\begin{array}{c}
x_{h_{p}}\\
y_{h_{p}}\\
z_{h_{p}}\\
w_{h_{p}}
\end{array}\right]=\left[\begin{array}{cccc}
\frac{1}{ar*tan(\frac{\alpha}{2})} & 0 & 0 & 0\\
0 & \frac{1}{tan(\frac{\alpha}{2})} & 0 & 0\\
0 & 0 & \frac{-(z_{n}+z_{f})}{(z_{n}-z_{f})} & \frac{2z_{n}z_{f}}{(z_{n}-z_{f})}\\
0 & 0 & 1 & 0
\end{array}\right]\left[\begin{array}{c}
x\\
y\\
z\\
1
\end{array}\right]
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $ar=\frac{screen\,width}{screen\,height}$
\end_inset

= aspect ratio of the projection plane,
\end_layout

\begin_layout Standard
\begin_inset Formula $\alpha$
\end_inset

 is the perspective angle of the vision sensor, 
\end_layout

\begin_layout Standard
\begin_inset Formula $z_{n}$
\end_inset

 is the near clipping distance of the vision sensor, 
\end_layout

\begin_layout Standard
\begin_inset Formula $z_{f}$
\end_inset

 is the far clipping distance of the vision sensor, the distance between
 the vision sensor and its projection plane,
\end_layout

\begin_layout Standard
\begin_inset Formula $w_{h_{p}}$
\end_inset

 stores the value of z during the transformation.
\end_layout

\begin_layout Standard
\begin_inset Formula $ar,\,\alpha,\,z_{n},\,z_{f}$
\end_inset

 are parameters of the vision sensor and were set to 1 (128x128 pixels),
 90
\begin_inset Formula $\textdegree$
\end_inset

, 0.02m, 2m respectively.
\end_layout

\begin_layout Itemize
projection plane coordinates are calculated using:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\begin{array}{c}
x_{p}=\frac{x_{h_{p}}}{w_{h_{p}}}*ar*\frac{\pi}{2}\\
y_{p}=\frac{y{}_{h_{p}}}{w_{h_{p}}}*\frac{\pi}{2}
\end{array}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
Multiplying 
\begin_inset Formula $x_{h_{p}}$
\end_inset

with 
\begin_inset Formula $ar$
\end_inset

 normalizes the range of 
\begin_inset Formula $x_{p}$
\end_inset

 to lie within 
\begin_inset Formula $(-ar,\,ar)$
\end_inset

 and restores the aspect ratio of the projection plane.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $y_{h_{p}}$
\end_inset

 ranges between (-1, 1).
\end_layout

\begin_layout Standard
The x-axis of the projection plane is assumed to scan the whole visual space,
 180
\begin_inset Formula $\textdegree$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Formula $x_{p},\,y_{p}$
\end_inset

 are converted to radians of eccentricity by multiple with 
\begin_inset Formula $\frac{\pi}{2}$
\end_inset

.
\end_layout

\begin_layout Itemize
The projection plane size of an object in radians of eccentricity is given
 by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
size_{p}=\frac{\pi*size}{2*ar*z_{e}*tan\left(\frac{\alpha}{2}\right)}
\]

\end_inset


\end_layout

\begin_layout Standard
where
\end_layout

\begin_layout Standard
\begin_inset Formula $size$
\end_inset

 is the real world size of the object,
\end_layout

\begin_layout Standard
\begin_inset Formula $z_{e}$
\end_inset

 is the Euclidean distance of the object from the vision sensor,
\end_layout

\begin_layout Standard
and we have use the relationship 
\begin_inset Formula $2*ar=\pi$
\end_inset

 to convert to radians of eccentricity.
\end_layout

\begin_layout Itemize
The orientation of an object is found by querying its Euler rotation angles
 (
\begin_inset Formula $\alpha,\,\beta,\,\gamma$
\end_inset

) with respect to the vision sensors frame.
\end_layout

\begin_layout Itemize
The vision sensor itself is rotated by 
\begin_inset Formula $\beta=90\textdegree,\,\gamma=90\textdegree$
\end_inset

 such that the vision sensors z-axis is along the real world x-axis (direction
 of motion of the IT cortex robot), y-axis is along the real world z-axis
 (vertical) and the x-axis is in the direction of the real world y-axis.
\end_layout

\begin_layout Itemize
By getting the rotations with respect to the vision sensors reference frame,
 rotations of the vision sensor with respect to the real world reference
 frame can be ignored.
\end_layout

\begin_layout Itemize

\emph on
However, it is useful to know that rotations about the real world x-axis,
 map to rotations around the vertical y-axis of vision sensor.
 The IT cortex model defines rotation tuning profiles about the vision sensors
 y-axis only.
 Rotations of the objects around the other axis map onto rotations around
 the y and z axis.
\end_layout

\begin_layout Itemize
A VREP child script is used to find the visibilities of the diagnostic and
 nondiagnostic parts of all objects.
\end_layout

\begin_layout Itemize
Each simulation step object handles for all objects and their component
 parts are passed to the child script.
 
\end_layout

\begin_layout Itemize
The vision sensor is configured to multiplex the object handle of each pixel
 with its value (in Vision sensor properties the Render mode field is set
 to OpenGL, color coded handles).
 
\emph on
The latest version of VREP has render mode which can be set to ray traced
 image.
 This should return the object handle of each pixel.
 However, since this part is already working we do not use the ray traced
 render mode
\emph default
.
\end_layout

\begin_layout Itemize
Once all objects that lie in the projection plane are determined, their
 handles fare sent to the child script.
 The child script decodes the object handle of each pixel and counts the
 number of visible pixels for each object.
\end_layout

\begin_layout Itemize
For each object, the script removes all other objects from the scene (by
 marking them as unrenderable), reacquires its projection image and counts
 the total number of object pixels.
\end_layout

\begin_layout Itemize
The ratio of visible to total pixels is used to determine visibilities levels
 of each object.
\end_layout

\begin_layout Itemize
Diagnostic parts of object are treated as a separate object thereby allowing
 the script to retrieve diagnostic parts visibilities as well.
\end_layout

\begin_layout Itemize
Once all ground truth is extracted it is fed into the IT Cortex model and
 the firing rate of each neuron is found.
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Subsection
Selectivity
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Selectivity Neuron Selectivity And Population Sparseness.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Neuron selectivity and population sparseness distributions.
 (A) Neuronal selectivity histogram.
 N=Number of model neurons.
 Average excess Kurtosis=3.37.
 (B) Population Sparseness histogram.
 N= Number of test stimuli.
 Average excess Kurtosis=12.04.
 We generated similar sized population of IT neurons and test stimuli set
 and successfully reproduced the result that population sparseness is greater
 than neuron selectivity seen in 
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011"

\end_inset

 with our adjusted parameter distributions.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:NeuronalSelectivityAndPopulationSparsness"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Selectivity Object Selectivites for Population.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Plot of ranked normalized object selectivity of neurons in a generated populatio
n.
 Objects with the highest selectivities are plotted first.
 
\emph on
Similar to Figure 2 in 
\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

.
 Does this figure add any value?
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Maximum Firing Rate
\end_layout

\begin_layout Itemize

\emph on
Include plot of mean firing rate vs selectivity, similar to Fig 5a of 
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2011"

\end_inset

.
 Log plot, shows firing rate decreases with selectivity defined as Kurtosis.
\end_layout

\begin_layout Subsection
Position
\end_layout

\begin_layout Itemize
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:RF Center Distributions"

\end_inset

 plots receptive field centers across a generated population with receptive
 field centers found in 
\begin_inset CommandInset citation
LatexCommand cite
key "op2000"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Position Receptive Field Center Distribution.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Distribution of Receptive Field centers around the center of gaze.
 Extracted data from 
\begin_inset CommandInset citation
LatexCommand cite
key "op2000"

\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig:RF Center Distributions"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Figures/Position Tolerance Distribution.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Postion Tolerance verses Selectivity.

\emph on
 
\emph default

\begin_inset CommandInset citation
LatexCommand cite
key "zoccolan2007"

\end_inset

 found a negative correlation between activity fraction selectivity and
 position tolerance of a neuron.
 As the neuron become more selective its position tolerance decreased -
 IT neurons that respond to objects are not grandmother cells.
 In this respect, IT neurons also differ from top level nodes of convolutional
 neuronal networks which have been compared with IT neurons but are designed
 to be position invariant.

\emph on
 Explain why the there are no activity fractions higher that 0.6 in the generated
 but have been seen in recordings of IT neurons.
 Consequence of using gamma distribution model to generate selectivity profiles?
 Increases the population size or the number of test stimuli still does
 not generate activity fractions greater than 0.6.
 
\emph default

\begin_inset CommandInset label
LatexCommand label
name "fig:Postion tolerence vs selectivity"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Size
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Figures/Size Tuning Curves Fits.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Types of size tuning profiles found in IT cortex and lognormal fits.
 (A) Example neuron with narrow tuning (size bandwidth < 2 octaves).
 (B) Example neuron with broad tuning (size bandwidth > 5 octaves).
 (c) Example neuron that only showed significant response to the largest
 stimulus size tested.
 Original data from 
\begin_inset CommandInset citation
LatexCommand cite
key "ito1995"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Size Tuning Profiles"

\end_inset

.
 
\emph on
Fix figure why is there a caption within the caption.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Figures/Size Preferred Size Distribution.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Distribution and histogram of preferred stimulus size of IT neurons.
 Original data from Ito et.
 al - 1995.
 
\emph on
This figure isn't very useful only data fitting.
 Should include generated data distribution as a comparison.
 Also two different fits are shown gamma and lognormal.
 This is not explained in the text and should be added.
 How else to improve? Fix figure why is there a caption within the caption.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Figures/Size Bandwidth distribution.svg
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Distribution and histogram of size bandwidths of IT neurons.
 Original data from Ito et.
 al - 1995.
 
\emph on
This figure isn't very useful, only data fitting.
 Should include generated data distribution as a comparison.
 Also two different fits are shown gamma and lognormal.
 This is not explained in the text and should be added.
 How else to improve?
\emph default
 
\emph on
Fix figure why is there a caption within the caption.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Orientation
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center

\emph on
Need to generate figure.
\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Rotation tuning profiles for objects with various rotation symmetries.
 In 
\begin_inset CommandInset citation
LatexCommand cite
key "ito1995"

\end_inset

, three types of rotation tuning profiles were found: single peak, bimodal
 and invariant (A) No mirror symmetry and no symmetry period (single peak
 - most objects), (B) Mirror symmetry but no symmetry period (bimodal -
 faces, cars), (C) Mirror symmetry and symmetric period of 4 (Cube (multiple
 peaks)), (D) Mirror Symmetry and symmetric period of 360
\begin_inset Formula $\textdegree$
\end_inset

 (view invariant).
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Occlusion
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Figures/Occlusion Tuning Profile.svg
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Sample Occlusion Tuning Profile.
 We fit our occlusion model to the normalized responses of object ranked
 1 in the moving occluder data tuning curve of 
\begin_inset CommandInset citation
LatexCommand cite
key "kovacs1995"

\end_inset

 and found the best fit 
\begin_inset Formula $w_{c}$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

.
 Given a diagnostic parts preference, 
\begin_inset Formula $R$
\end_inset

, we used nonlinear optimization to determine a set of 
\begin_inset Formula $w_{d}$
\end_inset

 and 
\begin_inset Formula $w_{nd}$
\end_inset

 that can generate R.
 See methods section for details.
 As noted in
\begin_inset CommandInset citation
LatexCommand cite
key "nielsen2006"

\end_inset

, both diagnostic and nondiagnostic parts are needed to get the unoccluded
 firing rate.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Clutter
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Figures/clutter profile.png
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\emph on
Fill me in
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Dynamic
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename Figures/Dynamic Profile.png
	scale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\emph on
Fill me in.
 Displayed Kurtosis values are incorrect.
 These are using the normalized firing to calculating Kurtosis.
 Should use the normalized firing rates times the max firing rate.
 Redo.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Discussion
\end_layout

\begin_layout Itemize
Comparison with other methods of 
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "kay2011"

\end_inset

 representation in visual system can be classified into three categories:
 
\end_layout

\begin_deeper
\begin_layout Itemize
Tuning Curve measurements: Isolate a single stimulus dimension.
 Measure responses to stimuli that vary along that dimension.
\end_layout

\begin_layout Itemize
Multivariate pattern classification: Again isolate a single stimulus, vary
 stimulus along the dimension, but look at multiple neuron responses and
 train a classifier to predict the dimension of interest from measured responses.
\end_layout

\begin_layout Itemize
Receptive field Estimation measure responses to a large number of stimuli
 that vary along multiple dimensions.
 Develop a single model that models responses over multiple dimensions.
 Example Gabor filter, looks at spatial freqency, contrast/amplitude and
 orientation.
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "kay2011"

\end_inset

, problems with tuning curve measurement results
\end_layout

\begin_deeper
\begin_layout Itemize
difficult to isolate stimuli dimensions.
\end_layout

\begin_layout Itemize
isolated stimulus may not be the actual dimension that IT neurons are responded
 to, it may be correlated to the actual stimulus dimension.
\end_layout

\begin_layout Itemize
difficult to generalize results
\end_layout

\end_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "kay2011"

\end_inset

 issues with developing a single receptive field model for inferior temporal
 neurons
\end_layout

\begin_deeper
\begin_layout Itemize
high dimensional space
\end_layout

\begin_layout Itemize
IT responds to complex stimuli which cannot be uniquely quantified.
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
How many tuning curves and object attributes to consider before the IT cortex
 model can approach the real IT Cortex
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset CommandInset citation
LatexCommand cite
key "lehky2014"

\end_inset

 estimated the intrinsic dimensionality of the IT cortex to be 93
\begin_inset Formula $\pm11$
\end_inset

SD.
\end_layout

\begin_layout Itemize
Most papers use stimuli sample sizes and record from neurons smaller than
 this dimensionally.
 
\emph on
so what?
\end_layout

\begin_layout Itemize
Difficult to come up with a single receptive field model (with multiple
 stimuli dimensions) as IT neurons deal with high dimensional stimuli only
 a few of which have been identified and even fewer have been completely
 understood.
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "bibtex"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
